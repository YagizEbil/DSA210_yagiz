{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each .csv folder to combined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: data/2024-11-28 12-48-19.csv\n",
      "Loaded file: data/2024-12-10 12-18-00.csv\n",
      "Loaded file: data/2024-11-29 07-42-09.csv\n",
      "Loaded file: data/2024-12-02 07-29-41.csv\n",
      "Loaded file: data/2024-11-14 10-26-54.csv\n",
      "Loaded file: data/2024-12-03 11-20-34.csv\n",
      "Loaded file: data/2024-12-13 22-27-09.csv\n",
      "Loaded file: data/2024-12-03 16-45-25.csv\n",
      "Loaded file: data/2024-11-13 07-35-32.csv\n",
      "Loaded file: data/2024-12-12 07-31-01.csv\n",
      "Loaded file: data/2024-11-15 20-23-56.csv\n",
      "Loaded file: data/2024-11-18 22-51-37.csv\n",
      "Loaded file: data/2024-12-10 21-50-08.csv\n",
      "Loaded file: data/2024-11-29 22-59-23.csv\n",
      "Loaded file: data/2024-11-26 13-15-04.csv\n",
      "Loaded file: data/2024-12-20 21-54-43.csv\n",
      "Loaded file: data/2024-12-14 07-53-22.csv\n",
      "Loaded file: data/2024-12-05 21-54-46.csv\n",
      "Loaded file: data/2024-12-22 10-18-11.csv\n",
      "Loaded file: data/2024-11-18 07-30-17.csv\n",
      "Loaded file: data/2024-12-18 20-28-23.csv\n",
      "Loaded file: data/2024-11-15 07-01-47.csv\n",
      "Loaded file: data/2024-11-28 16-48-37.csv\n",
      "Loaded file: data/2024-11-13 07-28-24.csv\n",
      "Loaded file: data/2024-12-19 23-55-21.csv\n",
      "Loaded file: data/2024-12-05 07-41-37.csv\n",
      "Loaded file: data/2024-11-26 13-06-58.csv\n",
      "Loaded file: data/2024-12-19 07-29-54.csv\n",
      "Loaded file: data/2024-11-13 07-33-07.csv\n",
      "Loaded file: data/2024-12-18 10-23-13.csv\n",
      "Loaded file: data/2024-12-14 14-59-02.csv\n",
      "Loaded file: data/2024-11-08 22-13-49.csv\n",
      "Loaded file: data/2024-12-09 07-34-34.csv\n",
      "Loaded file: data/2024-11-20 07-26-29.csv\n",
      "Loaded file: data/2024-11-20 22-13-00.csv\n",
      "Loaded file: data/2024-12-06 07-39-21.csv\n",
      "Loaded file: data/2024-12-20 07-38-51.csv\n",
      "Loaded file: data/2024-12-03 10-24-38.csv\n",
      "Loaded file: data/2024-11-14 11-25-44.csv\n",
      "Loaded file: data/2024-12-03 22-29-21.csv\n",
      "Loaded file: data/2024-12-01 17-08-37.csv\n",
      "Loaded file: data/2024-11-19 22-25-24.csv\n",
      "Loaded file: data/2024-12-04 20-53-42.csv\n",
      "Loaded file: data/2024-12-05 07-34-25.csv\n",
      "Loaded file: data/2024-11-26 21-58-57.csv\n",
      "Loaded file: data/2024-11-27 22-40-11.csv\n",
      "Loaded file: data/2024-11-13 08-22-58.csv\n",
      "Loaded file: data/2024-11-30 19-36-35.csv\n",
      "Loaded file: data/2024-12-12 16-33-38.csv\n",
      "Loaded file: data/2024-12-02 22-18-03.csv\n",
      "Loaded file: data/2024-12-01 09-05-00.csv\n",
      "Loaded file: data/2024-12-13 07-36-13.csv\n",
      "Loaded file: data/2024-12-06 21-09-46.csv\n",
      "Loaded file: data/2024-11-30 20-32-22.csv\n",
      "Loaded file: data/2024-11-27 07-33-56.csv\n",
      "Loaded file: data/2024-12-18 20-27-31.csv\n",
      "Loaded file: data/2024-11-30 19-24-27.csv\n",
      "Loaded file: data/2024-11-19 10-45-01.csv\n",
      "Loaded file: data/2024-12-11 21-53-19.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "\n",
    "folder_path = \"data\"\n",
    "files = glob.glob(f\"{folder_path}/*.csv\")\n",
    "\n",
    "dataframes_dict = {}  \n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    date = file.split('/')[-1].split(' ')[0]\n",
    "    time = file.split('/')[-1].split(' ')[1].split('.')[0]\n",
    "    print(f\"Loaded file: {file}\")\n",
    "    dataframes_dict[f\"{date} {time}\"] = df\n",
    "\n",
    "combined_df = pd.concat(dataframes_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECONDS</th>\n",
       "      <th>PID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGTITUDE</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28411.683627</td>\n",
       "      <td>Average speed (GPS)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>km/h</td>\n",
       "      <td>40.914741</td>\n",
       "      <td>29.193722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28411.683627</td>\n",
       "      <td>Speed (GPS)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>km/h</td>\n",
       "      <td>40.914741</td>\n",
       "      <td>29.193722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28411.690627</td>\n",
       "      <td>Altitude (GPS)</td>\n",
       "      <td>123.5</td>\n",
       "      <td>m</td>\n",
       "      <td>40.914741</td>\n",
       "      <td>29.193722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28411.697627</td>\n",
       "      <td>Altitude (GPS)</td>\n",
       "      <td>123.5</td>\n",
       "      <td>m</td>\n",
       "      <td>40.914741</td>\n",
       "      <td>29.193722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28411.697627</td>\n",
       "      <td>Average speed (GPS)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>km/h</td>\n",
       "      <td>40.914741</td>\n",
       "      <td>29.193722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SECONDS                  PID  VALUE UNITS   LATITUDE  LONGTITUDE  \\\n",
       "0  28411.683627  Average speed (GPS)    0.0  km/h  40.914741   29.193722   \n",
       "1  28411.683627          Speed (GPS)    0.0  km/h  40.914741   29.193722   \n",
       "2  28411.690627       Altitude (GPS)  123.5     m  40.914741   29.193722   \n",
       "3  28411.697627       Altitude (GPS)  123.5     m  40.914741   29.193722   \n",
       "4  28411.697627  Average speed (GPS)    0.0  km/h  40.914741   29.193722   \n",
       "\n",
       "   Unnamed: 6  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data/2024-12-14 07-53-22.csv\n",
    "df = dataframes_dict['2024-12-14 07-53-22']\n",
    "# Ensure the necessary columns are present and correctly formatted\n",
    "df['VALUE'] = pd.to_numeric(df['VALUE'], errors='coerce')\n",
    "df['SECONDS'] = pd.to_numeric(df['SECONDS'], errors='coerce')\n",
    "df['PID'] = df['PID'].astype(str)\n",
    "\n",
    "# Create an array that stores each PID then create a dictionary that stores each PID and its corresponding values with seconds\n",
    "PID = df['PID'].unique()\n",
    "PID_dict = {}\n",
    "for i in PID:\n",
    "    PID_dict[i] = pd.Series(df[df['PID'] == i]['VALUE'].values, index=df[df['PID'] == i]['SECONDS'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagizebil/Developer/DSA210_yagiz/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#lets create a map view of the data using the location data and the folium library\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "m = folium.Map(location=[df['LATITUDE'].mean(), df['LONGTITUDE'].mean()], zoom_start=12)\n",
    "\n",
    "heat_data = [[row['LATITUDE'],row['LONGTITUDE']] for index, row in df.iterrows()]\n",
    "\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "m.save('map.html')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the df has a column with Latitude and Longitude, add it to the map and create a combined map with all the data\n",
    "\n",
    "m = folium.Map(location=[df['LATITUDE'].mean(), df['LONGTITUDE'].mean()], zoom_start=15)\n",
    "\n",
    "for date_time, df in dataframes_dict.items():\n",
    "    if 'LATITUDE' in df.columns and 'LONGTITUDE' in df.columns:\n",
    "        heat_data = [[row['LATITUDE'], row['LONGTITUDE']] for index, row in df.iterrows()]\n",
    "        HeatMap(heat_data).add_to(m)\n",
    "\n",
    "m.save('map_all.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph for PID = PID\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Initial DataFrame:\\n\", df.head())\n",
    "\n",
    "df['VALUE'] = pd.to_numeric(df['VALUE'], errors='coerce')\n",
    "df['SECONDS'] = pd.to_numeric(df['SECONDS'], errors='coerce')\n",
    "df['PID'] = df['PID'].astype(str)\n",
    "df['VALUE'] = df['VALUE'].astype(float)\n",
    "df['SECONDS'] = df['SECONDS'].astype(float)\n",
    "\n",
    "i = 'Speed (GPS)'\n",
    "df = pd.DataFrame(PID_dict[i])\n",
    "plt.plot((PID_dict[i].index - PID_dict[i].index[0])/60, PID_dict[i].values, label=i)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(i)\n",
    "plt.title(i + ' over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "df = dataframes_dict['2024-12-14 07-53-22']\n",
    "\n",
    "#create int num\n",
    "num = 0\n",
    "for pid in PID:\n",
    "    print(num)\n",
    "    print(pid)\n",
    "    num = num + 1\n",
    "\n",
    "#df contains all values under PID column, so we need to extract the values for the specific PIDs we are interested in\n",
    "check_one = PID[0]\n",
    "check_two = PID[1]\n",
    "one = df[df['PID'] == check_one]\n",
    "two = df[df['PID'] == check_two]\n",
    "\n",
    "#reindex the dataframes\n",
    "one = one.reset_index(drop=True)\n",
    "two = two.reset_index(drop=True)\n",
    "\n",
    "#make all values numeric\n",
    "one['VALUE'] = pd.to_numeric(one['VALUE'], errors='coerce').fillna(0)\n",
    "two['VALUE'] = pd.to_numeric(two['VALUE'], errors='coerce').fillna(0)\n",
    "\n",
    "#make the count of the values the same, take average of the values to make the count the same\n",
    "while len(one) > len(two):\n",
    "    one = one.drop(one.index[1]).reset_index(drop=True)\n",
    "while len(two) > len(one):\n",
    "    random_index = random.randint(0, len(two)-2)\n",
    "    two = two.drop(two.index[random_index+1]).reset_index(drop=True)\n",
    "\n",
    "#plot the values single plot\n",
    "plt.plot(one['VALUE'], label=check_one)\n",
    "plt.plot(two['VALUE'], label=check_two)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f\"{check_one} vs {check_two}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(one['VALUE'], two['VALUE'])\n",
    "plt.xlabel(check_one)\n",
    "plt.ylabel(check_two)\n",
    "plt.title(f\"{check_one} vs {check_two}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate gradio\n",
    "import gradio as gr\n",
    "\n",
    "def plot_values(PID1, PID2):\n",
    "    one = df[df['PID'] == PID1]\n",
    "    two = df[df['PID'] == PID2]\n",
    "    one = one.reset_index(drop=True)\n",
    "    two = two.reset_index(drop=True)\n",
    "    one['VALUE'] = pd.to_numeric(one['VALUE'], errors='coerce').fillna(0)\n",
    "    two['VALUE'] = pd.to_numeric(two['VALUE'], errors='coerce').fillna(0)\n",
    "    while len(one) > len(two):\n",
    "        one = one.drop(one.index[1]).reset_index(drop=True)\n",
    "    while len(two) > len(one):\n",
    "        random_index = random.randint(0, len(two)-2)\n",
    "        two = two.drop(two.index[random_index+1]).reset_index(drop=True)\n",
    "    plt.plot(one['VALUE'], label=PID1)\n",
    "    plt.plot(two['VALUE'], label=PID2)\n",
    "    plt.xlabel('Index')\n",
    "    plt.title(f\"{PID1} vs {PID2}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.scatter(one['VALUE'], two['VALUE'])\n",
    "    plt.xlabel(PID1)\n",
    "    plt.ylabel(PID2)\n",
    "    plt.title(f\"{PID1} vs {PID2}\")\n",
    "    plt.show()\n",
    "\n",
    "PID1 = gr.Dropdown(list(PID), label=\"PID1\")\n",
    "PID2 = gr.Dropdown(list(PID), label=\"PID2\")\n",
    "\n",
    "gr.Interface(plot_values, [PID1, PID2], \"plot\").launch()\n",
    "gr.Plot(plot_values(PID1, PID2)).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hyptothesis test for the data\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a function that takes in two PIDs and returns the p-value of a t-test\n",
    "\n",
    "def t_test(PID1, PID2):\n",
    "    one = df[df['PID'] == PID1]\n",
    "    two = df[df['PID'] == PID2]\n",
    "    one = one.reset_index(drop=True)\n",
    "    two = two.reset_index(drop=True)\n",
    "    one['VALUE'] = pd.to_numeric(one['VALUE'], errors='coerce').fillna(0)\n",
    "    two['VALUE'] = pd.to_numeric(two['VALUE'], errors='coerce').fillna(0)\n",
    "    while len(one) > len(two):\n",
    "        one = one.drop(one.index[1]).reset_index(drop=True)\n",
    "    while len(two) > len(one):\n",
    "        random_index = random.randint(0, len(two)-2)\n",
    "        two = two.drop(two.index[random_index+1]).reset_index(drop=True)\n",
    "    t_stat, p_value = stats.ttest_ind(one['VALUE'], two['VALUE'])\n",
    "    return p_value\n",
    "\n",
    "PID1 = gr.Dropdown(list(PID), label=\"PID1\")\n",
    "PID2 = gr.Dropdown(list(PID), label=\"PID2\")\n",
    "\n",
    "gr.Interface(t_test, [PID1, PID2], \"number\").launch()\n",
    "gr.Interface(t_test, [PID1, PID2], \"number\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Average speed (GPS)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     one[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALUE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(one[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALUE\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m     one[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSECONDS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(one[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSECONDS\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     correlation_each_pid[pid] \u001b[38;5;241m=\u001b[39m \u001b[43mone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#plot the correlation matrix\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/DSA210_yagiz/venv/lib/python3.9/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/Developer/DSA210_yagiz/venv/lib/python3.9/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Developer/DSA210_yagiz/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/Developer/DSA210_yagiz/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Average speed (GPS)'"
     ]
    }
   ],
   "source": [
    "#create correlation matrix for each pid\n",
    "correlation_each_pid = {}\n",
    "for pid in PID:\n",
    "    one = df[df['PID'] == pid]\n",
    "    one = one.reset_index(drop=True)\n",
    "    one['VALUE'] = pd.to_numeric(one['VALUE'], errors='coerce').fillna(0)\n",
    "    one['SECONDS'] = pd.to_numeric(one['SECONDS'], errors='coerce').fillna(0)\n",
    "    correlation_each_pid[pid] = one.corr()\n",
    "\n",
    "#plot the correlation matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
